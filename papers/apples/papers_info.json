{
  "2202.11372v1": {
    "title": "Localizing Small Apples in Complex Apple Orchard Environments",
    "authors": [
      "Christian Wilms",
      "Robert Johanson",
      "Simone Frintrop"
    ],
    "summary": "The localization of fruits is an essential first step in automated\nagricultural pipelines for yield estimation or fruit picking. One example of\nthis is the localization of apples in images of entire apple trees. Since the\napples are very small objects in such scenarios, we tackle this problem by\nadapting the object proposal generation system AttentionMask that focuses on\nsmall objects. We adapt AttentionMask by either adding a new module for very\nsmall apples or integrating it into a tiling framework. Both approaches clearly\noutperform standard object proposal generation systems on the MinneApple\ndataset covering complex apple orchard environments. Our evaluation further\nanalyses the improvement w.r.t. the apple sizes and shows the different\ncharacteristics of our two approaches.",
    "pdf_url": "http://arxiv.org/pdf/2202.11372v1",
    "published": "2022-02-23"
  },
  "2110.03232v1": {
    "title": "Design of an Intelligent Vision Algorithm for Recognition and Classification of Apples in an Orchard Scene",
    "authors": [
      "Hamid Majidi Balanji",
      "Alaeedin Rahmani Didar",
      "Mohamadali Hadad Derafshi"
    ],
    "summary": "Apple is one of the remarkable fresh fruit that contains a high degree of\nnutritious and medicinal value. Hand harvesting of apples by seasonal\nfarmworkers increases physical damages on the surface of these fruits, which\ncauses a great loss in marketing quality. The main objective of this study is\nfocused on designing a robust vision algorithm for robotic apple harvesters.\nThe proposed algorithm is able to recognize and classify 4-classes of objects\nfound in an orchard scene including apples, leaves, trunk and branches, and sky\ninto two apples and non-apples classes. 100 digital images of Red Delicious\napples and 100 digital images of Golden Delicious apples were selected among\n1000 captured images of apples from 18 apple gardens in West Azerbaijan, Iran.\nAn image processing algorithm is proposed for segmentation and extraction of\nthe image classes based on the color characteristics of mentioned classes.\nInvariant-Momentums were chosen as the extracted features from the segmented\nclasses, e.g. apples. Multilayer Feedforward Neural Networks, MFNNs, were used\nas an artificial intelligence tool for the recognition and classification of\nimage classes.",
    "pdf_url": "http://arxiv.org/pdf/2110.03232v1",
    "published": "2021-10-07"
  },
  "2303.04884v1": {
    "title": "O2RNet: Occluder-Occludee Relational Network for Robust Apple Detection in Clustered Orchard Environments",
    "authors": [
      "Pengyu Chu",
      "Zhaojian Li",
      "Kaixiang Zhang",
      "Dong Chen",
      "Kyle Lammers",
      "Renfu Lu"
    ],
    "summary": "Automated apple harvesting has attracted significant research interest in\nrecent years due to its potential to revolutionize the apple industry,\naddressing the issues of shortage and high costs in labor. One key technology\nto fully enable efficient automated harvesting is accurate and robust apple\ndetection, which is challenging due to complex orchard environments that\ninvolve varying lighting conditions and foliage/branch occlusions. Furthermore,\nclustered apples are common in the orchard, which brings additional challenges\nas the clustered apples may be identified as one apple. This will cause issues\nin localization for subsequent robotic operations. In this paper, we present\nthe development of a novel deep learning-based apple detection framework,\nOccluder-Occludee Relational Network (O2RNet), for robust detection of apples\nin such clustered environments. This network exploits the occuluder-occludee\nrelationship modeling head by introducing a feature expansion structure to\nenable the combination of layered traditional detectors to split clustered\napples and foliage occlusions. More specifically, we collect a comprehensive\napple orchard image dataset under different lighting conditions (overcast,\nfront lighting, and back lighting) with frequent apple occlusions. We then\ndevelop a novel occlusion-aware network for apple detection, in which a feature\nexpansion structure is incorporated into the convolutional neural networks to\nextract additional features generated by the original network for occluded\napples. Comprehensive evaluations are performed, which show that the developed\nO2RNet outperforms state-of-the-art models with a higher accuracy of 94\\% and a\nhigher F1-score of 0.88 on apple detection.",
    "pdf_url": "http://arxiv.org/pdf/2303.04884v1",
    "published": "2023-03-08"
  },
  "1706.06640v2": {
    "title": "Comment on \"Graphene---A rather ordinary nonlinear optical material\" [Appl. Phys. Lett. \\textbf{104}, 161116 (2014)]",
    "authors": [
      "S. A. Mikhailov"
    ],
    "summary": "A comment on the paper Appl. Phys. Lett. 104, 161116 (2014).",
    "pdf_url": "http://arxiv.org/pdf/1706.06640v2",
    "published": "2017-06-20"
  },
  "1608.04303v1": {
    "title": "SandBlaster: Reversing the Apple Sandbox",
    "authors": [
      "R\u0103zvan Deaconescu",
      "Luke Deshotels",
      "Mihai Bucicoiu",
      "William Enck",
      "Lucas Davi",
      "Ahmad-Reza Sadeghi"
    ],
    "summary": "In order to limit the damage of malware on Mac OS X and iOS, Apple uses\nsandboxing, a kernel-level security layer that provides tight constraints for\nsystem calls. Particularly used for Apple iOS, sandboxing prevents apps from\nexecuting potentially dangerous actions, by defining rules in a sandbox\nprofile. Investigating Apple's built-in sandbox profiles is difficult as they\nare compiled and stored in binary format. We present SandBlaster, a software\nbundle that is able to reverse/decompile Apple binary sandbox profiles to their\noriginal human readable SBPL (SandBox Profile Language) format. We use\nSandBlaster to reverse all built-in Apple iOS binary sandbox profiles for iOS\n7, 8 and 9. Our tool is, to the best of our knowledge, the first to provide a\nfull reversing of the Apple sandbox, shedding light into the inner workings of\nApple sandbox profiles and providing essential support for security researchers\nand professionals interested in Apple security mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/1608.04303v1",
    "published": "2016-08-15"
  }
}